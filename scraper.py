import requests
import re
import asyncio
import aiohttp
from datetime import datetime
from urllib.parse import urlparse, quote

import requests
import base64
import re
import os
from datetime import datetime

# –û–ì–†–û–ú–ù–´–ô –°–ü–ò–°–û–ö –ò–°–¢–û–ß–ù–ò–ö–û–í (—Å–æ–±–∏—Ä–∞–µ–º –æ—Ç–æ–≤—Å—é–¥—É)
SOURCES = [
    "https://livpn.atwebpages.com/sub.php?token=3b4cbb400a537740",
    "https://subrostunnel.vercel.app/gen.txt",
    "https://gitverse.ru/api/repos/Vsevj/OBS/raw/branch/master/wwh",
    "https://raw.githubusercontent.com/CidVpn/cid-vpn-config/refs/heads/main/general.txt",
    "https://raw.githubusercontent.com/LimeHi/LimeVPN/refs/heads/main/LimeVPN.txt"
]

def decode_content(text):
    """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç Base64, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –∫–∞–∫ –µ—Å—Ç—å"""
    try:
        # –ü—Ä–æ–±—É–µ–º –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞—Ç—å (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏ —Ü–µ–ª–∏–∫–æ–º –≤ base64)
        return base64.b64decode(text).decode('utf-8')
    except:
        return text

def scrape():
    raw_configs = []
    
    print("üöÄ –ù–∞—á–∏–Ω–∞—é –º–∞—Å—à—Ç–∞–±–Ω—ã–π —Å–±–æ—Ä...")
    
    for url in SOURCES:
        try:
            print(f"üì° –ó–∞–ø—Ä–æ—Å –∫: {url}")
            res = requests.get(url, timeout=15)
            if res.status_code == 200:
                content = decode_content(res.text)
                # –ò—â–µ–º –≤—Å—ë, —á—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –∫–æ–Ω—Ñ–∏–≥ —á–µ—Ä–µ–∑ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
                found = re.findall(r'(vless://|vmess://|trojan://|ss://|ssr://)[\w\-\.\%\?\=\&\#\:\/]+', content)
                
                # –°–æ–±–∏—Ä–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –æ–±—Ä–∞—Ç–Ω–æ –≤ –ø–æ–ª–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏
                lines = content.splitlines()
                current_found = 0
                for line in lines:
                    line = line.strip()
                    if any(line.startswith(p) for p in ['vless://', 'vmess://', 'trojan://', 'ss://', 'ssr://']):
                        raw_configs.append(line)
                        current_found += 1
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ: {current_found}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ {url}: {e}")

    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_configs = list(set(raw_configs))
    
    # –ì–†–£–ü–ü–ò–†–û–í–ö–ê –ü–û –ü–†–û–¢–û–ö–û–õ–ê–ú (–∫–∞–∫ —Ç—ã –ø—Ä–æ—Å–∏–ª)
    vless = [c for c in unique_configs if c.startswith('vless://')]
    trojan = [c for c in unique_configs if c.startswith('trojan://')]
    ss = [c for c in unique_configs if c.startswith('ss://')]
    ssr = [c for c in unique_configs if c.startswith('ssr://')]
    vmess = [c for c in unique_configs if c.startswith('vmess://')]
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –≤ —Å—Ç—Ä–æ–≥–æ–º –ø–æ—Ä—è–¥–∫–µ
    final_output = vless + trojan + ss + ssr + vmess
    
    if not final_output:
        print("‚ò†Ô∏è –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ! –ü—Ä–æ–≤–µ—Ä—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏.")
        return

    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ–¥–ø–∏—Å–∫–∏
    with open("sub.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(final_output))
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Ä–µ–º—è –¥–ª—è —Ç–∞–π–º–µ—Ä–∞ (–≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ)
    with open("last_update.txt", "w", encoding="utf-8") as f:
        f.write(datetime.now().isoformat())
        
    print(f"üèÅ –£—Å–ø–µ—Ö! –°–æ–±—Ä–∞–Ω–æ –≤—Å–µ–≥–æ: {len(final_output)}")
    print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: VLESS:{len(vless)}, Trojan:{len(trojan)}, SS:{len(ss)}, VMess:{len(vmess)}")

if __name__ == "__main__":
    scrape()

def get_flag_emoji(country_code):
    if not country_code or len(country_code) != 2:
        return None
    return "".join(chr(127397 + ord(c)) for c in country_code.upper())

async def get_country_info(session, ip):
    try:
        async with session.get(f"http://ip-api.com/json/{ip}?fields=status,countryCode,country", timeout=2) as resp:
            data = await resp.json()
            if data.get('status') == 'success':
                return data['countryCode'], data['country']
    except: pass
    return None, None

async def check_and_rename(session, url, counter):
    try:
        clean_url = url.split('#')[0]
        proto = clean_url.split('://')[0].lower()
        
        if proto == 'vmess':
            host, port = "1.1.1.1", 443 # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è vmess
        else:
            parsed = urlparse(clean_url.replace(f'{proto}://', 'http://'))
            host, port = parsed.hostname, (parsed.port if parsed.port else 443)

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä—Ç–∞
        try:
            conn = asyncio.open_connection(host, port)
            reader, writer = await asyncio.wait_for(conn, timeout=2.0)
            writer.close()
            await writer.wait_closed()
        except: return None

        code, name = await get_country_info(session, host)
        flag = get_flag_emoji(code)
        
        if flag and name:
            key = f"{flag} {proto.upper()} {name}"
            counter[key] = counter.get(key, 0) + 1
            new_name = f"{key} {counter[key]}"
            sort_key = f"0_{name}_{proto}_{counter[key]}"
        else:
            counter["Unknown"] = counter.get("Unknown", 0) + 1
            new_name = f"üåê {proto.upper()} Unknown Node {counter['Unknown']}"
            sort_key = f"1_Unknown_{proto}_{counter['Unknown']}"

        return (f"{clean_url}#{quote(new_name)}", sort_key)
    except: return None

async def main():
    raw_configs = set()
    pattern = r'(?:vless|vmess|trojan|ss|ssr)://[^\s]+'
    
    for url in SOURCES:
        try:
            r = requests.get(url, timeout=10)
            raw_configs.update(re.findall(pattern, r.text, re.IGNORECASE))
        except: continue

    country_counter = {}
    async with aiohttp.ClientSession() as session:
        tasks = [check_and_rename(session, conf, country_counter) for conf in raw_configs]
        results = await asyncio.gather(*tasks)
    
    valid = sorted([r for r in results if r is not None], key=lambda x: x[1])
    final_links = [item[0] for item in valid]

    with open("sub.txt", "w", encoding="utf-8") as f:
        f.write("\n".join(final_links))
    
    with open("last_update.txt", "w") as f:
        f.write(datetime.now().isoformat())
    
    print(f"Done! Servers: {len(final_links)}")

if __name__ == "__main__":
    asyncio.run(main())
